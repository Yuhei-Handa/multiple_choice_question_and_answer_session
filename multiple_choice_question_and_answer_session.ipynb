{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee681ab899643d5a18476a3b6017cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe882b562a704abaa0d801f49c020069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/488k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807442e4e7b04abcbd2cf2f844eda89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/62.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e1dff92166410cb9b097459bb8ba59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e3b26dd1944608b6dc778f2ca79a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6969c10f9ade4082be199dec4a8de426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#多肢選択式応答\n",
    "\n",
    "from pprint import pprint\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\n",
    "    \"llm-book/JGLUE\", name=\"JCommonsenseQA\", split=\"train\"\n",
    ")\n",
    "\n",
    "valid_dataset = load_dataset(\n",
    "    \"llm-book/JGLUE\", name=\"JCommonsenseQA\", split=\"validation\"    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choice0': '世界',\n",
      " 'choice1': '写真集',\n",
      " 'choice2': '絵本',\n",
      " 'choice3': '論文',\n",
      " 'choice4': '図鑑',\n",
      " 'label': 2,\n",
      " 'q_id': 0,\n",
      " 'question': '主に子ども向けのもので、イラストのついた物語が書かれているものはどれ？'}\n",
      "\n",
      "{'choice0': '浮浪者',\n",
      " 'choice1': '保護者',\n",
      " 'choice2': 'お坊さん',\n",
      " 'choice3': '宗教者',\n",
      " 'choice4': '預言者',\n",
      " 'label': 1,\n",
      " 'q_id': 1,\n",
      " 'question': '未成年者を監護・教育し，彼らを監督し，彼らの財産上の利益を守る法律上の義務をもつ人は？'}\n",
      "\n",
      "{'choice0': '成金',\n",
      " 'choice1': '関白',\n",
      " 'choice2': '同僚',\n",
      " 'choice3': 'クリップボード',\n",
      " 'choice4': '成功者',\n",
      " 'label': 4,\n",
      " 'q_id': 10,\n",
      " 'question': '物事を成しとげた人は？'}\n"
     ]
    }
   ],
   "source": [
    "#データセットの確認\n",
    "\n",
    "pprint(train_dataset[0])\n",
    "print()\n",
    "pprint(train_dataset[1])\n",
    "print()\n",
    "pprint(train_dataset[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23012b9bdd9043018a71f9f9853ac802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\yuhei\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da63a9fbfd9b4fe987e697a6a4e8b993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6834c9d3daca4e4795b2c71861e3868d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"llm-book/bert-base-japanese-v3-jcommonsenseqa\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f6813b6e3041da98d4501d3bb19a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8939 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9812fc6bb37f47b9ad89b54c084ae0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#多肢選択式のデータセットに対する前処理\n",
    "\n",
    "from transformers import BatchEncoding\n",
    "\n",
    "num_choice = train_dataset.features[\"label\"].num_classes\n",
    "\n",
    "def preprocess_multi_process(example, num_choice):\n",
    "    choice_list = [example[f\"choice{i}\"] for i in range(num_choice)]\n",
    "    question_list = [example[\"question\"]] * num_choice\n",
    "\n",
    "    encoded_example = tokenizer(question_list, choice_list, max_length=128)\n",
    "\n",
    "    if \"label\" in example:\n",
    "        encoded_example[\"labels\"] = example[\"label\"]\n",
    "\n",
    "    return encoded_example\n",
    "\n",
    "\n",
    "encoded_train_dataset = train_dataset.map(\n",
    "    lambda example: preprocess_multi_process(example, num_choice=num_choice), remove_columns=train_dataset.column_names\n",
    ")\n",
    "encoded_valid_dataset = valid_dataset.map(\n",
    "    lambda example: preprocess_multi_process(example, num_choice=num_choice), remove_columns=train_dataset.column_names\n",
    ")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '主に', '子ども', '向け', 'の', 'もの', 'で', '、', 'イラスト', 'の', 'つい', 'た', '物語', 'が', '書か', 'れ', 'て', 'いる', 'もの', 'は', 'どれ', '?', '[SEP]', '世界', '[SEP]']\n",
      "['[CLS]', '主に', '子ども', '向け', 'の', 'もの', 'で', '、', 'イラスト', 'の', 'つい', 'た', '物語', 'が', '書か', 'れ', 'て', 'いる', 'もの', 'は', 'どれ', '?', '[SEP]', '写真', '集', '[SEP]']\n",
      "['[CLS]', '主に', '子ども', '向け', 'の', 'もの', 'で', '、', 'イラスト', 'の', 'つい', 'た', '物語', 'が', '書か', 'れ', 'て', 'いる', 'もの', 'は', 'どれ', '?', '[SEP]', '絵本', '[SEP]']\n",
      "['[CLS]', '主に', '子ども', '向け', 'の', 'もの', 'で', '、', 'イラスト', 'の', 'つい', 'た', '物語', 'が', '書か', 'れ', 'て', 'いる', 'もの', 'は', 'どれ', '?', '[SEP]', '論文', '[SEP]']\n",
      "['[CLS]', '主に', '子ども', '向け', 'の', 'もの', 'で', '、', 'イラスト', 'の', 'つい', 'た', '物語', 'が', '書か', 'れ', 'て', 'いる', 'もの', 'は', 'どれ', '?', '[SEP]', '図鑑', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "#tokenizerの処理を確認\n",
    "\n",
    "example = train_dataset[0]\n",
    "\n",
    "encoded_example = preprocess_multi_process(example, num_choice)\n",
    "\n",
    "for i in range(5):\n",
    "    print(tokenizer.convert_ids_to_tokens(encoded_example[\"input_ids\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [[1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1],\n",
      "                    [1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1],\n",
      "                    [1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1],\n",
      "                    [1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1],\n",
      "                    [1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1]],\n",
      " 'input_ids': [[2,\n",
      "                13182,\n",
      "                16044,\n",
      "                12994,\n",
      "                464,\n",
      "                12518,\n",
      "                457,\n",
      "                384,\n",
      "                14930,\n",
      "                464,\n",
      "                12584,\n",
      "                449,\n",
      "                13360,\n",
      "                430,\n",
      "                14220,\n",
      "                494,\n",
      "                456,\n",
      "                12483,\n",
      "                12518,\n",
      "                465,\n",
      "                19382,\n",
      "                46,\n",
      "                3,\n",
      "                12575,\n",
      "                3],\n",
      "               [2,\n",
      "                13182,\n",
      "                16044,\n",
      "                12994,\n",
      "                464,\n",
      "                12518,\n",
      "                457,\n",
      "                384,\n",
      "                14930,\n",
      "                464,\n",
      "                12584,\n",
      "                449,\n",
      "                13360,\n",
      "                430,\n",
      "                14220,\n",
      "                494,\n",
      "                456,\n",
      "                12483,\n",
      "                12518,\n",
      "                465,\n",
      "                19382,\n",
      "                46,\n",
      "                3,\n",
      "                13409,\n",
      "                6460,\n",
      "                3],\n",
      "               [2,\n",
      "                13182,\n",
      "                16044,\n",
      "                12994,\n",
      "                464,\n",
      "                12518,\n",
      "                457,\n",
      "                384,\n",
      "                14930,\n",
      "                464,\n",
      "                12584,\n",
      "                449,\n",
      "                13360,\n",
      "                430,\n",
      "                14220,\n",
      "                494,\n",
      "                456,\n",
      "                12483,\n",
      "                12518,\n",
      "                465,\n",
      "                19382,\n",
      "                46,\n",
      "                3,\n",
      "                20647,\n",
      "                3],\n",
      "               [2,\n",
      "                13182,\n",
      "                16044,\n",
      "                12994,\n",
      "                464,\n",
      "                12518,\n",
      "                457,\n",
      "                384,\n",
      "                14930,\n",
      "                464,\n",
      "                12584,\n",
      "                449,\n",
      "                13360,\n",
      "                430,\n",
      "                14220,\n",
      "                494,\n",
      "                456,\n",
      "                12483,\n",
      "                12518,\n",
      "                465,\n",
      "                19382,\n",
      "                46,\n",
      "                3,\n",
      "                15252,\n",
      "                3],\n",
      "               [2,\n",
      "                13182,\n",
      "                16044,\n",
      "                12994,\n",
      "                464,\n",
      "                12518,\n",
      "                457,\n",
      "                384,\n",
      "                14930,\n",
      "                464,\n",
      "                12584,\n",
      "                449,\n",
      "                13360,\n",
      "                430,\n",
      "                14220,\n",
      "                494,\n",
      "                456,\n",
      "                12483,\n",
      "                12518,\n",
      "                465,\n",
      "                19382,\n",
      "                46,\n",
      "                3,\n",
      "                22929,\n",
      "                3]],\n",
      " 'labels': 2,\n",
      " 'token_type_ids': [[0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     1,\n",
      "                     1],\n",
      "                    [0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     1,\n",
      "                     1,\n",
      "                     1],\n",
      "                    [0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     1,\n",
      "                     1],\n",
      "                    [0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     1,\n",
      "                     1],\n",
      "                    [0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     0,\n",
      "                     1,\n",
      "                     1]]}\n"
     ]
    }
   ],
   "source": [
    "pprint(encoded_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ミニバッチ化と最大長パディングを実行する関数\n",
    "from transformers import BatchEncoding\n",
    "import torch\n",
    "\n",
    "def collate_multiple_choice(features):\n",
    "\n",
    "    batch_size = len(features)\n",
    "    num_choice = len(features[0][\"input_ids\"])\n",
    "\n",
    "    label_name = \"labels\"\n",
    "\n",
    "    flat_list = []\n",
    "    for feature in features:\n",
    "        flat_list += [{\n",
    "           k:v[i]  for k, v in feature.items() \n",
    "           if k != \"labels\" \n",
    "        } for i in range(num_choice)]\n",
    "\n",
    "    flat_batch = tokenizer.pad(flat_list, return_tensors=\"pt\")\n",
    "\n",
    "    batch = {k:v.view(batch_size, num_choice, -1)  for k, v in flat_batch.items()}\n",
    "\n",
    "    if label_name in features[0].keys():\n",
    "        labels = [feature[label_name] for feature in features]\n",
    "        batch[label_name] = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-v3 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMultipleChoice\n",
    "\n",
    "transformers_model_name = \"cl-tohoku/bert-base-japanese-v3\"\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(transformers_model_name, \n",
    "                                                   num_labels=train_dataset.features[\"label\"].num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, BatchEncoding\n",
    "import numpy as np\n",
    "\n",
    "def calc_accuracy(eval_pred):\n",
    "\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\"accuracy\":(predictions == labels).mean()}\n",
    "\n",
    "training_arg = TrainingArguments(\n",
    "    output_dir=\"./output/\",\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_ratio=0.1,\n",
    "    num_train_epochs=5,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_valid_dataset,\n",
    "    data_collator=collate_multiple_choice,\n",
    "    compute_metrics=calc_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2a8f7be6bd4d7f919a593d5a6ee5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3354 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7161, 'learning_rate': 4.2620751341681574e-05, 'epoch': 0.45}\n",
      "{'loss': 0.6248, 'learning_rate': 3.5166964818127615e-05, 'epoch': 0.89}\n",
      "{'loss': 0.3324, 'learning_rate': 2.7713178294573645e-05, 'epoch': 1.34}\n",
      "{'loss': 0.2431, 'learning_rate': 2.025939177101968e-05, 'epoch': 1.79}\n",
      "{'loss': 0.1621, 'learning_rate': 1.2805605247465712e-05, 'epoch': 2.24}\n",
      "{'loss': 0.081, 'learning_rate': 5.3518187239117475e-06, 'epoch': 2.68}\n",
      "{'train_runtime': 273.9501, 'train_samples_per_second': 97.89, 'train_steps_per_second': 12.243, 'train_loss': 0.3308519262178497, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3354, training_loss=0.3308519262178497, metrics={'train_runtime': 273.9501, 'train_samples_per_second': 97.89, 'train_steps_per_second': 12.243, 'train_loss': 0.3308519262178497, 'epoch': 3.0})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e49ce3937f46a8a0eb30dbb21a34fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7758638262748718,\n",
       " 'eval_accuracy': 0.8400357462019661,\n",
       " 'eval_runtime': 2.852,\n",
       " 'eval_samples_per_second': 392.351,\n",
       " 'eval_steps_per_second': 49.088,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
